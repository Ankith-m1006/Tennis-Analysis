{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import models,transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "from cv2 import cvtColor,COLOR_BGR2RGB\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import cvtColor,COLOR_BGR2RGB\n",
    "class KeypointsDataset(Dataset):\n",
    "    def __init__(self, img_dir, data_file):\n",
    "        self.img_dir = img_dir\n",
    "        with open(data_file,'r')as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229,0.224,0.225])\n",
    "\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "       item = self.data[idx]\n",
    "       img = cv2.imread(f\"{self.img_dir}/{item['id']}.png\")\n",
    "       h,w = img.shape[:2]\n",
    "\n",
    "       img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "       img = self.transforms(img)\n",
    "       kps = np.array(item['kps']).flatten()\n",
    "       kps = kps.astype(np.float32)\n",
    "\n",
    "       kps[::2] *= 224.0/w\n",
    "       kps[1::2] *= 224.0/h\n",
    "\n",
    "       return img,kps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KeypointsDataset(r\"C:\\Users\\ankit\\Downloads\\tennis_court_det_dataset\\data\\images\", r\"C:\\Users\\ankit\\Downloads\\tennis_court_det_dataset\\data\\data_train.json\")\n",
    "val_dataset = KeypointsDataset(r\"C:\\Users\\ankit\\Downloads\\tennis_court_det_dataset\\data\\images\", r\"C:\\Users\\ankit\\Downloads\\tennis_court_det_dataset\\data\\data_val.json\")\n",
    "train_loader = DataLoader(train_dataset,batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ankit\\OneDrive\\Desktop\\Tennis\\tennis.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ankit\\OneDrive\\Desktop\\Tennis\\tennis.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained = True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features,14*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1/2, step 1/(829,)Loss:14765.150390625\n",
      "Epoch1/2, step 11/(829,)Loss:14457.443359375\n",
      "Epoch1/2, step 21/(829,)Loss:13217.5322265625\n",
      "Epoch1/2, step 31/(829,)Loss:13391.662109375\n",
      "Epoch1/2, step 41/(829,)Loss:13920.8896484375\n",
      "Epoch1/2, step 51/(829,)Loss:12575.0478515625\n",
      "Epoch1/2, step 61/(829,)Loss:13334.6357421875\n",
      "Epoch1/2, step 71/(829,)Loss:13253.0556640625\n",
      "Epoch1/2, step 81/(829,)Loss:12018.9921875\n",
      "Epoch1/2, step 91/(829,)Loss:11780.7314453125\n",
      "Epoch1/2, step 101/(829,)Loss:10776.1650390625\n",
      "Epoch1/2, step 111/(829,)Loss:11047.1611328125\n",
      "Epoch1/2, step 121/(829,)Loss:10602.5390625\n",
      "Epoch1/2, step 131/(829,)Loss:10306.9716796875\n",
      "Epoch1/2, step 141/(829,)Loss:9954.6884765625\n",
      "Epoch1/2, step 151/(829,)Loss:9652.5068359375\n",
      "Epoch1/2, step 161/(829,)Loss:8904.2939453125\n",
      "Epoch1/2, step 171/(829,)Loss:8641.1953125\n",
      "Epoch1/2, step 181/(829,)Loss:8537.583984375\n",
      "Epoch1/2, step 191/(829,)Loss:8206.2265625\n",
      "Epoch1/2, step 201/(829,)Loss:7463.18505859375\n",
      "Epoch1/2, step 211/(829,)Loss:7822.09814453125\n",
      "Epoch1/2, step 221/(829,)Loss:6810.07275390625\n",
      "Epoch1/2, step 231/(829,)Loss:6978.8037109375\n",
      "Epoch1/2, step 241/(829,)Loss:6820.51806640625\n",
      "Epoch1/2, step 251/(829,)Loss:6510.59228515625\n",
      "Epoch1/2, step 261/(829,)Loss:6134.36865234375\n",
      "Epoch1/2, step 271/(829,)Loss:5564.14404296875\n",
      "Epoch1/2, step 281/(829,)Loss:5754.4169921875\n",
      "Epoch1/2, step 291/(829,)Loss:5158.36669921875\n",
      "Epoch1/2, step 301/(829,)Loss:5036.71435546875\n",
      "Epoch1/2, step 311/(829,)Loss:4961.58984375\n",
      "Epoch1/2, step 321/(829,)Loss:4888.25341796875\n",
      "Epoch1/2, step 331/(829,)Loss:4424.9365234375\n",
      "Epoch1/2, step 341/(829,)Loss:4175.55419921875\n",
      "Epoch1/2, step 351/(829,)Loss:4422.35400390625\n",
      "Epoch1/2, step 361/(829,)Loss:3900.01611328125\n",
      "Epoch1/2, step 371/(829,)Loss:3629.85888671875\n",
      "Epoch1/2, step 381/(829,)Loss:3515.753173828125\n",
      "Epoch1/2, step 391/(829,)Loss:3584.137451171875\n",
      "Epoch1/2, step 401/(829,)Loss:3336.91552734375\n",
      "Epoch1/2, step 411/(829,)Loss:2937.958984375\n",
      "Epoch1/2, step 421/(829,)Loss:2880.606689453125\n",
      "Epoch1/2, step 431/(829,)Loss:2742.835693359375\n",
      "Epoch1/2, step 441/(829,)Loss:2538.68701171875\n",
      "Epoch1/2, step 451/(829,)Loss:2414.649658203125\n",
      "Epoch1/2, step 461/(829,)Loss:3423.612060546875\n",
      "Epoch1/2, step 471/(829,)Loss:2264.26806640625\n",
      "Epoch1/2, step 481/(829,)Loss:2029.5980224609375\n",
      "Epoch1/2, step 491/(829,)Loss:1940.9678955078125\n",
      "Epoch1/2, step 501/(829,)Loss:2035.2843017578125\n",
      "Epoch1/2, step 511/(829,)Loss:2060.863525390625\n",
      "Epoch1/2, step 521/(829,)Loss:1567.249267578125\n",
      "Epoch1/2, step 531/(829,)Loss:1713.7293701171875\n",
      "Epoch1/2, step 541/(829,)Loss:1425.851318359375\n",
      "Epoch1/2, step 551/(829,)Loss:1901.635009765625\n",
      "Epoch1/2, step 561/(829,)Loss:1331.1846923828125\n",
      "Epoch1/2, step 571/(829,)Loss:1131.80517578125\n",
      "Epoch1/2, step 581/(829,)Loss:1159.4920654296875\n",
      "Epoch1/2, step 591/(829,)Loss:1236.107666015625\n",
      "Epoch1/2, step 601/(829,)Loss:1200.4385986328125\n",
      "Epoch1/2, step 611/(829,)Loss:1097.009033203125\n",
      "Epoch1/2, step 621/(829,)Loss:878.8682861328125\n",
      "Epoch1/2, step 631/(829,)Loss:985.6725463867188\n",
      "Epoch1/2, step 641/(829,)Loss:997.3572387695312\n",
      "Epoch1/2, step 651/(829,)Loss:823.0278930664062\n",
      "Epoch1/2, step 661/(829,)Loss:782.3004760742188\n",
      "Epoch1/2, step 671/(829,)Loss:759.12890625\n",
      "Epoch1/2, step 681/(829,)Loss:744.5695190429688\n",
      "Epoch1/2, step 691/(829,)Loss:805.5559692382812\n",
      "Epoch1/2, step 701/(829,)Loss:543.0732421875\n",
      "Epoch1/2, step 711/(829,)Loss:467.2049255371094\n",
      "Epoch1/2, step 721/(829,)Loss:586.5802001953125\n",
      "Epoch1/2, step 731/(829,)Loss:375.8824768066406\n",
      "Epoch1/2, step 741/(829,)Loss:416.95001220703125\n",
      "Epoch1/2, step 751/(829,)Loss:600.0390625\n",
      "Epoch1/2, step 761/(829,)Loss:317.43267822265625\n",
      "Epoch1/2, step 771/(829,)Loss:396.99798583984375\n",
      "Epoch1/2, step 781/(829,)Loss:327.15716552734375\n",
      "Epoch1/2, step 791/(829,)Loss:330.7419128417969\n",
      "Epoch1/2, step 801/(829,)Loss:286.2961730957031\n",
      "Epoch1/2, step 811/(829,)Loss:213.3284912109375\n",
      "Epoch1/2, step 821/(829,)Loss:328.8442687988281\n",
      "Epoch2/2, step 1/(829,)Loss:202.5897216796875\n",
      "Epoch2/2, step 11/(829,)Loss:206.16200256347656\n",
      "Epoch2/2, step 21/(829,)Loss:232.96511840820312\n",
      "Epoch2/2, step 31/(829,)Loss:166.42054748535156\n",
      "Epoch2/2, step 41/(829,)Loss:539.8611450195312\n",
      "Epoch2/2, step 51/(829,)Loss:151.7536163330078\n",
      "Epoch2/2, step 61/(829,)Loss:142.96849060058594\n",
      "Epoch2/2, step 71/(829,)Loss:172.3642120361328\n",
      "Epoch2/2, step 81/(829,)Loss:136.8586883544922\n",
      "Epoch2/2, step 91/(829,)Loss:94.900390625\n",
      "Epoch2/2, step 101/(829,)Loss:135.87892150878906\n",
      "Epoch2/2, step 111/(829,)Loss:217.23153686523438\n",
      "Epoch2/2, step 121/(829,)Loss:132.3492889404297\n",
      "Epoch2/2, step 131/(829,)Loss:61.14676284790039\n",
      "Epoch2/2, step 141/(829,)Loss:81.7282943725586\n",
      "Epoch2/2, step 151/(829,)Loss:103.56561279296875\n",
      "Epoch2/2, step 161/(829,)Loss:117.25420379638672\n",
      "Epoch2/2, step 171/(829,)Loss:59.93146896362305\n",
      "Epoch2/2, step 181/(829,)Loss:80.32698822021484\n",
      "Epoch2/2, step 191/(829,)Loss:66.9305191040039\n",
      "Epoch2/2, step 201/(829,)Loss:47.46209716796875\n",
      "Epoch2/2, step 211/(829,)Loss:71.11405181884766\n",
      "Epoch2/2, step 221/(829,)Loss:78.46977233886719\n",
      "Epoch2/2, step 231/(829,)Loss:50.16830062866211\n",
      "Epoch2/2, step 241/(829,)Loss:67.58023834228516\n",
      "Epoch2/2, step 251/(829,)Loss:61.937015533447266\n",
      "Epoch2/2, step 261/(829,)Loss:43.29762649536133\n",
      "Epoch2/2, step 271/(829,)Loss:73.12709045410156\n",
      "Epoch2/2, step 281/(829,)Loss:31.768749237060547\n",
      "Epoch2/2, step 291/(829,)Loss:112.35869598388672\n",
      "Epoch2/2, step 301/(829,)Loss:75.80547332763672\n",
      "Epoch2/2, step 311/(829,)Loss:145.703125\n",
      "Epoch2/2, step 321/(829,)Loss:53.66475296020508\n",
      "Epoch2/2, step 331/(829,)Loss:45.64983367919922\n",
      "Epoch2/2, step 341/(829,)Loss:47.73593521118164\n",
      "Epoch2/2, step 351/(829,)Loss:62.195316314697266\n",
      "Epoch2/2, step 361/(829,)Loss:29.788761138916016\n",
      "Epoch2/2, step 371/(829,)Loss:30.56016731262207\n",
      "Epoch2/2, step 381/(829,)Loss:53.9101676940918\n",
      "Epoch2/2, step 391/(829,)Loss:79.09553527832031\n",
      "Epoch2/2, step 401/(829,)Loss:41.59965896606445\n",
      "Epoch2/2, step 411/(829,)Loss:45.42929458618164\n",
      "Epoch2/2, step 421/(829,)Loss:26.681833267211914\n",
      "Epoch2/2, step 431/(829,)Loss:50.464420318603516\n",
      "Epoch2/2, step 441/(829,)Loss:58.419429779052734\n",
      "Epoch2/2, step 451/(829,)Loss:51.15827560424805\n",
      "Epoch2/2, step 461/(829,)Loss:64.02982330322266\n",
      "Epoch2/2, step 471/(829,)Loss:64.08663177490234\n",
      "Epoch2/2, step 481/(829,)Loss:28.78325843811035\n",
      "Epoch2/2, step 491/(829,)Loss:22.428640365600586\n",
      "Epoch2/2, step 501/(829,)Loss:121.60028839111328\n",
      "Epoch2/2, step 511/(829,)Loss:46.02029800415039\n",
      "Epoch2/2, step 521/(829,)Loss:39.21038818359375\n",
      "Epoch2/2, step 531/(829,)Loss:33.3023796081543\n",
      "Epoch2/2, step 541/(829,)Loss:92.05696105957031\n",
      "Epoch2/2, step 551/(829,)Loss:131.93270874023438\n",
      "Epoch2/2, step 561/(829,)Loss:42.92015838623047\n",
      "Epoch2/2, step 571/(829,)Loss:34.792442321777344\n",
      "Epoch2/2, step 581/(829,)Loss:19.34205436706543\n",
      "Epoch2/2, step 591/(829,)Loss:41.97089385986328\n",
      "Epoch2/2, step 601/(829,)Loss:47.3360710144043\n",
      "Epoch2/2, step 611/(829,)Loss:30.308048248291016\n",
      "Epoch2/2, step 621/(829,)Loss:32.71799850463867\n",
      "Epoch2/2, step 631/(829,)Loss:44.24068069458008\n",
      "Epoch2/2, step 641/(829,)Loss:80.04009246826172\n",
      "Epoch2/2, step 651/(829,)Loss:38.27143096923828\n",
      "Epoch2/2, step 661/(829,)Loss:81.62043762207031\n",
      "Epoch2/2, step 671/(829,)Loss:42.61997604370117\n",
      "Epoch2/2, step 681/(829,)Loss:30.230331420898438\n",
      "Epoch2/2, step 691/(829,)Loss:28.400705337524414\n",
      "Epoch2/2, step 701/(829,)Loss:58.33560562133789\n",
      "Epoch2/2, step 711/(829,)Loss:43.06856155395508\n",
      "Epoch2/2, step 721/(829,)Loss:31.014129638671875\n",
      "Epoch2/2, step 731/(829,)Loss:26.77321434020996\n",
      "Epoch2/2, step 741/(829,)Loss:40.953392028808594\n",
      "Epoch2/2, step 751/(829,)Loss:20.78754234313965\n",
      "Epoch2/2, step 761/(829,)Loss:71.1964340209961\n",
      "Epoch2/2, step 771/(829,)Loss:58.742008209228516\n",
      "Epoch2/2, step 781/(829,)Loss:28.216360092163086\n",
      "Epoch2/2, step 791/(829,)Loss:59.78760528564453\n",
      "Epoch2/2, step 801/(829,)Loss:47.99884796142578\n",
      "Epoch2/2, step 811/(829,)Loss:37.76157760620117\n",
      "Epoch2/2, step 821/(829,)Loss:37.996665954589844\n"
     ]
    }
   ],
   "source": [
    "epochs=2\n",
    "for epoch in range(epochs):\n",
    "    for i, (img,kps) in enumerate(train_loader):\n",
    "        img = img.to(device)\n",
    "        kps = kps.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img)\n",
    "        loss = criterion(outputs,kps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i%10 == 0:\n",
    "            print(f\"Epoch{epoch+1}/{epochs}, step {i+1}/{len(train_loader),}Loss:{loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"keypoints_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tennis.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
